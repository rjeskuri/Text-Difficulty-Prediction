{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-edgar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in ./.local/lib/python3.9/site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in ./.local/lib/python3.9/site-packages (from textstat) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b57bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./.local/lib/python3.9/site-packages (from spacy) (1.10.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in ./.local/lib/python3.9/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.local/lib/python3.9/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./.local/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.9/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./.local/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.9/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.9/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.local/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a2b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langdetect in ./.local/lib/python3.9/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import textstat\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c76a3db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_688502/3793406994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "veterinary-election",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ryanje/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ryanje/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ryanje/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/ryanje/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea80382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('WikiLarge_Train.csv')\n",
    "test_df = pd.read_csv('WikiLarge_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_aoa = pd.read_csv('AoA_51715_words.csv',encoding='Windows-1252')\n",
    "features_concrete = pd.read_csv('Concreteness_ratings_Brysbaert_et_al_BRM.txt',encoding='utf-8', delimiter = '\\t')\n",
    "features_dale_chall = pd.read_csv('dale_chall.txt',encoding='utf-8',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-jenny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frozen-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "# Initialize the lemmatizer and load Spacy's English model\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "#regex to clean the original text\n",
    "pattern = re.compile(r'\\-lrb\\-|\\-rrb\\-|\\b\\W\\b|\\n|_|\\s+')\n",
    "def clean_text(sentence):\n",
    "    # Lowercasing\n",
    "    sentence = sentence.lower()\n",
    "    # Applying compiled regular expression pattern\n",
    "    sentence = pattern.sub(' ', sentence)\n",
    "    # Stripping leading and trailing spaces\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Lemmatize the tokens\n",
    "def text_lemmatizer(token_text):\n",
    "    return [lemmatizer.lemmatize(word) for word in token_text]\n",
    "\n",
    "# dependency counts take way too long to create for minimal value\n",
    "# # Adding dependency parsing counts\n",
    "# def get_dependency_counts(text):\n",
    "#     doc = nlp(text)\n",
    "#     return Counter(tok.dep_ for tok in doc)\n",
    "\n",
    "# def add_dependency_counts(dataframe):\n",
    "#     dep_counts = dataframe['clean_text'].apply(get_dependency_counts)\n",
    "#     unique_deps = set(dep for counts in dep_counts for dep in counts.keys())\n",
    "#     for dep in unique_deps:\n",
    "#         dataframe[f'dep_{dep}_count'] = dep_counts.apply(lambda x: x.get(dep, 0))\n",
    "\n",
    "#add Parts of Speech counts, limited to some common ones as it takes a long time to run\n",
    "def add_pos_counts(dataframe):\n",
    "    pos_counts = dataframe['tokens'].apply(lambda tokens: Counter(tag for word, tag in nltk.pos_tag(tokens)))\n",
    "    for tag in ['NN', 'VB', 'JJ', 'RB']:\n",
    "        dataframe[f'pos_{tag}_count'] = pos_counts.apply(lambda x: x.get(tag, 0))\n",
    "\n",
    "# Calculating entropy of sentence as a measure of how many unique words\n",
    "def lexical_diversity(text):\n",
    "    return -sum(freq/len(text) * math.log(freq/len(text), 2) for freq in Counter(text).values())\n",
    "\n",
    "# Function to sum how many words in a sentence have more than one meaning\n",
    "def count_multiple_meanings(tokens):\n",
    "    return sum(len(wordnet.synsets(word)) > 1 for word in tokens)\n",
    "\n",
    "# Function to calculate SMOG Index\n",
    "def calculate_smog_index(text):\n",
    "    # Using textstat library to calculate SMOG Index\n",
    "    return smog_index(text)\n",
    "\n",
    "# Function to calculate Type-Token Ratio (TTR)\n",
    "def calculate_type_token_ratio(tokens):\n",
    "    # Number of unique words\n",
    "    types = set(tokens)\n",
    "    # Type-Token Ratio\n",
    "    return len(types) / len(tokens) if len(tokens) > 0 else 0\n",
    "\n",
    "# Function to bin different readability tests into easy, average, or difficult texts\n",
    "def calculate_readability_features(dataframe):\n",
    "    \n",
    "    # Add logic for updating categories based on 'clean_text'\n",
    "    dataframe.loc[dataframe['clean_text'].isnull() | (dataframe['clean_text'] == 0), 'flesch_reading_ease_category'] = 2\n",
    "    dataframe.loc[dataframe['clean_text'].isnull() | (dataframe['clean_text'] == 0), 'gunning_fog_category'] = 1\n",
    "    dataframe.loc[dataframe['clean_text'].isnull() | (dataframe['clean_text'] == 0), 'smog_index_category'] = 2    \n",
    "    \n",
    "    # Flesch Reading Ease, higher score is easier to read\n",
    "    # Categories: 0 = Easy, 1 = Average, 2 = Difficult\n",
    "    dataframe['flesch_reading_ease'] = dataframe['clean_text'].apply(textstat.flesch_reading_ease)\n",
    "    dataframe['flesch_reading_ease_category'] = dataframe['flesch_reading_ease'].apply(lambda x: 0 if x > 70 else (2 if x < 60 else 1))\n",
    "    dataframe.drop(columns=['flesch_reading_ease'], inplace=True)\n",
    "\n",
    "    # Gunning Fog is age a reader should be to understand a sentence\n",
    "    # Categories: 0 = Easy, 1 = Average, 2 = Difficult\n",
    "    dataframe['gunning_fog'] = dataframe['clean_text'].apply(textstat.gunning_fog)\n",
    "    dataframe['gunning_fog_category'] = dataframe['gunning_fog'].apply(lambda x: 0 if x < 10 else (2 if x > 15 else 1))\n",
    "    dataframe.drop(columns=['gunning_fog'], inplace=True)\n",
    "\n",
    "    # Smog Index, similar to Gunning Fog\n",
    "    # Categories: 0 = Easy, 1 = Average, 2 = Difficult \n",
    "    dataframe['smog_index'] = dataframe['clean_text'].apply(textstat.smog_index)\n",
    "    dataframe['smog_index_category'] = dataframe['smog_index'].apply(lambda x: 0 if x < 10 else (2 if x > 15 else 1))\n",
    "    dataframe.drop(columns=['smog_index'], inplace=True)\n",
    "\n",
    "# Helper function for calculate_aoa_dalechall_features \n",
    "def calculate_additional_features(dataframe, average_aoa, dale_chall_lemmatized):\n",
    "    lemma_texts = dataframe['lemmatized_text'].str.split()\n",
    "    dale_chall_counts = lemma_texts.apply(lambda words: sum(word in dale_chall_lemmatized for word in words))\n",
    "    high_aoa_counts = lemma_texts.apply(lambda words: sum((word in average_aoa) and (average_aoa[word] > 9) for word in words))\n",
    "    low_aoa_counts = lemma_texts.apply(lambda words: sum((word in average_aoa) and (average_aoa[word] <= 9) for word in words))\n",
    "\n",
    "    return dale_chall_counts, high_aoa_counts, low_aoa_counts\n",
    "                                                                       \n",
    "                                                                       \n",
    "#function to calculate the counts of dale chall words and binned AoA words, lemmatized\n",
    "#AoA ages are rounded and averaged as sum words are the same after lemmatizing\n",
    "def calculate_aoa_dalechall_features(dataframe, features_aoa, features_dale_chall):\n",
    "    # AoA DaleChall features using lemmatized words\n",
    "    features_aoa.dropna(subset=['Word', 'AoA_Kup_lem'], inplace=True)\n",
    "    aoa_lemmatized = text_lemmatizer(features_aoa['Word'])\n",
    "    lemmatized_word_counts = {word: {'sum': 0, 'count': 0} for word in aoa_lemmatized}\n",
    "    for idx, (word, aoa) in enumerate(zip(aoa_lemmatized, features_aoa['AoA_Kup_lem'])):\n",
    "        lemmatized_word_counts[word]['sum'] += aoa\n",
    "        lemmatized_word_counts[word]['count'] += 1\n",
    "    average_aoa = {word: round(info['sum'] / info['count']) for word, info in lemmatized_word_counts.items()}\n",
    "    dale_chall_lemmatized = set(text_lemmatizer(features_dale_chall['a']))\n",
    "    \n",
    "    dale_chall_counts, high_aoa_counts, low_aoa_counts = calculate_additional_features(dataframe, average_aoa, dale_chall_lemmatized)\n",
    "    dataframe['dale_chall'] = dale_chall_counts\n",
    "    dataframe['high_aoa'] = high_aoa_counts\n",
    "    dataframe['low_aoa'] = low_aoa_counts\n",
    "\n",
    "# Function to calculate features from concretness dataset on lemmatized words\n",
    "def calculate_concreteness_features(dataframe, features_concrete):\n",
    "    # Concreteness features using lemmatized words\n",
    "    features_concrete['lemmatized_word'] = features_concrete['Word'].apply(lambda x: lemmatizer.lemmatize(x) if isinstance(x, str) else x)\n",
    "    grouped_concreteness = features_concrete.groupby('lemmatized_word').agg({'Conc.M': 'mean', 'SUBTLEX': 'mean'}).reset_index()\n",
    "    # Zipping features together to increase performance                                                                   \n",
    "    concreteness_dict = dict(zip(grouped_concreteness['lemmatized_word'], grouped_concreteness['Conc.M']))\n",
    "    subtlex_us_dict = dict(zip(grouped_concreteness['lemmatized_word'], grouped_concreteness['SUBTLEX']))\n",
    "    \n",
    "    # Using lemmatized text in the calculation of sentence features and using numpy arrays for faster calc\n",
    "    num_sentences = len(dataframe['lemmatized_text'])\n",
    "    concrete_count = np.zeros(num_sentences, dtype=int)\n",
    "    non_concrete_count = np.zeros(num_sentences, dtype=int)\n",
    "    mean_concreteness = np.zeros(num_sentences)\n",
    "    mean_subtlex_us_frequency = np.zeros(num_sentences)\n",
    "\n",
    "    for i, text in enumerate(dataframe['lemmatized_text']):\n",
    "        words = text.split()\n",
    "        concreteness_scores = [concreteness_dict[word] for word in words if word in concreteness_dict]\n",
    "        subtlex_us_frequencies = [subtlex_us_dict[word] for word in words if word in subtlex_us_dict]\n",
    "\n",
    "        if concreteness_scores:\n",
    "            mean_concreteness[i] = np.mean(concreteness_scores)\n",
    "            concrete_count[i] = sum(1 for score in concreteness_scores if score > 3)\n",
    "            non_concrete_count[i] = len(concreteness_scores) - concrete_count[i]\n",
    "\n",
    "        if subtlex_us_frequencies:\n",
    "            mean_subtlex_us_frequency[i] = np.mean(subtlex_us_frequencies)\n",
    "            \n",
    "    # Store features in the dataframe\n",
    "    dataframe['concrete_count'] = concrete_count\n",
    "    dataframe['non_concrete_count'] = non_concrete_count\n",
    "    dataframe['mean_concreteness'] = mean_concreteness\n",
    "    dataframe['mean_subtlex_us_frequency'] = mean_subtlex_us_frequency\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main function to extract features from a DataFrame\n",
    "def extract_features(dataframe, features_aoa, features_dale_chall, features_concrete):\n",
    "    \n",
    "    # Feature for Wikipedia markup LRB or RRB\n",
    "    dataframe['contains_wiki_markup'] = dataframe['original_text'].str.contains(r'-LRB-|-RRB-', regex=True).astype(int)\n",
    "    dataframe['is_numeric'] = dataframe['original_text'].apply(lambda x: ''.join(filter(str.isdigit, x)).isdigit()).astype(int)\n",
    "    # Feature for sentences that are only a punctuation mark\n",
    "    dataframe['only_punctuation'] = dataframe['original_text'].str.match(r'^\\W+$').astype(int)\n",
    "    print('done checking nums/punct/foreign words')\n",
    "    # Clean and tokenize text\n",
    "    dataframe['clean_text'] = dataframe['original_text'].apply(clean_text)\n",
    "    dataframe['tokens'] = dataframe['clean_text'].apply(lambda x: word_tokenize(x))\n",
    "    dataframe['lemmatized_text'] = dataframe['tokens'].apply(lambda x: \" \".join(text_lemmatizer(x)))\n",
    "    dataframe['only_markup'] = np.where(dataframe['clean_text'].isnull(), 1, 0)\n",
    "    print('done lemmatizing')\n",
    "   \n",
    "    # Word and character counts\n",
    "    dataframe['num_words'] = dataframe['tokens'].str.len()\n",
    "    dataframe['num_characters'] = dataframe['clean_text'].str.len()\n",
    "    dataframe['num_unique_words'] = dataframe['tokens'].apply(lambda x: len(set(x)))\n",
    "    dataframe['ratio_unique_total_words'] = dataframe['num_unique_words'] / dataframe['num_words']\n",
    "    dataframe['num_long_words'] = dataframe['tokens'].apply(lambda x: sum(1 for word in x if len(word) > 6))\n",
    "    dataframe['syllable_count'] = dataframe['clean_text'].apply(textstat.syllable_count)\n",
    "    dataframe['avg_syllables_per_word'] = dataframe['syllable_count'] / dataframe['num_words']\n",
    "    dataframe['lexical_diversity'] = dataframe['clean_text'].apply(lexical_diversity) \n",
    "    dataframe['type_toke_ration'] = dataframe['tokens'].apply(calculate_type_token_ratio)\n",
    "    dataframe['multiple_meanings_count'] = dataframe['tokens'].apply(count_multiple_meanings)\n",
    "    \n",
    "\n",
    "    print('done adding counts')\n",
    "#     #Depencdency Counts\n",
    "#     add_dependency_counts(dataframe)\n",
    "#     print('dependency counts')\n",
    "    # Parts of Speech Counts\n",
    "    add_pos_counts(dataframe)\n",
    "    print('pos counts')\n",
    "    # Readability features\n",
    "    calculate_readability_features(dataframe)\n",
    "    print('readability counts')\n",
    "    # AoA DaleChall features\n",
    "    calculate_aoa_dalechall_features(dataframe, features_aoa, features_dale_chall)\n",
    "    print('aoa and dalechall')\n",
    "    # Concreteness features\n",
    "    calculate_concreteness_features(dataframe, features_concrete)    \n",
    "    #some text is completely stripped, resulting in null calculations \n",
    "    dataframe.fillna(0, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-investment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done checking nums/punct/foreign words\n",
      "done lemmatizing\n",
      "done adding counts\n",
      "pos counts\n",
      "readability counts\n",
      "aoa and dalechall\n"
     ]
    }
   ],
   "source": [
    "train_df = extract_features(train_df,features_aoa, features_dale_chall, features_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sticky-qatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done checking nums/punct/foreign words\n",
      "done lemmatizing\n",
      "done adding counts\n",
      "pos counts\n",
      "readability counts\n",
      "aoa and dalechall\n"
     ]
    }
   ],
   "source": [
    "test_df = extract_features(test_df, features_aoa, features_dale_chall, features_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bb1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows_with_nulls(dataframe):\n",
    "    # Check for rows with null values\n",
    "    rows_with_nulls = dataframe[dataframe.isna().any(axis=1)]\n",
    "    \n",
    "    # If there are any rows with null values, print them\n",
    "    if not rows_with_nulls.empty:\n",
    "        print(\"Rows with null values:\")\n",
    "        print(rows_with_nulls)\n",
    "    else:\n",
    "        print(\"No rows with null values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governmental-garage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows with null values found.\n"
     ]
    }
   ],
   "source": [
    "print_rows_with_nulls(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f31ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No rows with null values found.\n"
     ]
    }
   ],
   "source": [
    "print_rows_with_nulls(test_df.drop('label',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greatest-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_df.pickle', 'wb') as f:\n",
    "    pickle.dump(train_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "square-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickled data\n",
    "with open('train_df.pickle', 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "covered-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_df.pickle', 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "front-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickled data\n",
    "with open('test_df.pickle', 'rb') as f:\n",
    "    test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-consumer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sufficient-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframes and remove all text for classifiers that don't use text\n",
    "def df_copy_nontext(df):\n",
    "    X = df.copy()\n",
    "    X = X.drop(['original_text','clean_text','tokens','lemmatized_text'],axis=1)\n",
    "    if 'id' in df.columns:\n",
    "        X = X.drop('id',axis=1)\n",
    "    y = X.pop('label')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = df_copy_nontext(train_df)\n",
    "X_test, _ = df_copy_nontext(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "superior-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "470194f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "#X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "detailed-mobility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.49843240130526584\n"
     ]
    }
   ],
   "source": [
    "# Create a DummyClassifier with a 'most_frequent' strategy\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dummy.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = dummy.predict(X_val_scaled_df)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy_score = accuracy_score(y_val, y_pred)\n",
    "print(\"F1:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953a3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e52ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6593907905783213\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=42, n_jobs=-1).fit(X_train_scaled_df,y_train)\n",
    "preds = lr_clf.predict(X_val_scaled_df)\n",
    "f1_score = f1_score(y_val, preds)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33365449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get feature names, assuming you are using DataFrame\n",
    "# feature_names = X_train_scaled_df.columns\n",
    "\n",
    "# # Get the coefficients from the trained model\n",
    "# coefficients = lr_clf.coef_[0]\n",
    "\n",
    "# # Combine feature names and coefficients into a DataFrame\n",
    "# feature_importances = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "\n",
    "# # Sort the features by the absolute value of their coefficient\n",
    "# feature_importances = feature_importances.reindex(feature_importances.coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# # Display the feature importances\n",
    "# print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cultural-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6684528631067356\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42,n_estimators=100,max_depth=5, n_jobs=-1).fit(X_train_scaled_df, y_train)\n",
    "preds = rf_clf.predict(X_val_scaled_df)\n",
    "f1_scores = f1_score(y_val, preds)\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fifth-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the classifier on the full training and validation set\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "lr_clf = LogisticRegression(random_state=42, n_jobs=-1).fit(X_scaled,y)\n",
    "\n",
    "# Predict X_test\n",
    "y_test_pred = lr_clf.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with 'id' and 'label' columns\n",
    "results_df = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('lr_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7863f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refit if needed for full data on random forest\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "rf_clf = RandomForestClassifier(random_state=42,n_estimators=100,max_depth=7, n_jobs=-1).fit(X_scaled,y)\n",
    "# Predict X_test\n",
    "y_test_pred = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with 'id' and 'label' columns\n",
    "results_df = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('rf_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98e534a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3504            9.32m\n",
      "         2           1.3203            9.30m\n",
      "         3           1.2949            9.23m\n",
      "         4           1.2737            9.21m\n",
      "         5           1.2551            9.16m\n",
      "         6           1.2391            9.12m\n",
      "         7           1.2252            9.07m\n",
      "         8           1.2129            9.03m\n",
      "         9           1.2018            8.99m\n",
      "        10           1.1920            8.94m\n",
      "        20           1.1300            8.52m\n",
      "        30           1.0948            8.07m\n",
      "        40           1.0717            7.64m\n",
      "        50           1.0554            7.21m\n",
      "        60           1.0432            6.77m\n",
      "        70           1.0322            6.32m\n",
      "        80           1.0219            5.86m\n",
      "        90           1.0109            5.38m\n",
      "0.7052010690915794\n"
     ]
    }
   ],
   "source": [
    "#max depth 10 and tol .001 did the best so far, trying deeper depth\n",
    "gb_model = GradientBoostingClassifier(n_estimators = 200, max_depth = 10,\n",
    "                                    random_state=42,verbose=1,n_iter_no_change=10,tol=0.001).fit(X_train_scaled_df,y_train)\n",
    "preds = gb_model.predict(X_val_scaled_df)\n",
    "f1_scores = f1_score(y_val, preds)\n",
    "print(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76569869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2825           42.27m\n",
      "         2           1.1923           46.84m\n",
      "         3           1.1124           49.74m\n",
      "         4           1.0395           52.05m\n",
      "         5           0.9763           53.35m\n",
      "         6           0.9184           54.43m\n",
      "         7           0.8662           55.12m\n",
      "         8           0.8180           55.84m\n",
      "         9           0.7745           56.33m\n",
      "        10           0.7334           56.79m\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "gb_model = GradientBoostingClassifier(n_estimators = 200, max_depth = 15,\n",
    "                                    random_state=42,verbose=1,n_iter_no_change=10,tol=0.001).fit(X_scaled,y)\n",
    "# Predict X_test\n",
    "y_test_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame with 'id' and 'label' columns\n",
    "results_df = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('gb_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da5355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep lemmatized sentence for text transformations\n",
    "def df_copy_text(df):\n",
    "    X = df.copy()\n",
    "    X = X.drop(['original_text','clean_text','tokens'],axis=1)\n",
    "    if 'id' in df.columns:\n",
    "        X = X.drop('id',axis=1)\n",
    "    y = X.pop('label')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = df_copy_text(train_df)\n",
    "X_test, _ = df_copy_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try combining tf-idf with other features, might need svd/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f504c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d521b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',min_df=60,max_df=0.8,strip_accents='unicode')\n",
    "X_train_tf = vectorizer.fit_transform(X_train['lemmatized_text'])\n",
    "X_val_tf = vectorizer.transform(X_val['lemmatized_text'])\n",
    "# Scale the data\n",
    "scaler_vec = StandardScaler(with_mean=False)  # use with_mean=False for sparse data\n",
    "\n",
    "scaled_tfidf_train = scaler_vec.fit_transform(X_train_tf)\n",
    "scaled_tfidf_val = scaler_vec.transform(X_val_tf)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdcb3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676994689359524\n"
     ]
    }
   ],
   "source": [
    "lr_clf_vec = LogisticRegression(random_state=42, n_jobs=-1).fit(scaled_tfidf_train,y_train)\n",
    "preds = lr_clf_vec.predict(scaled_tfidf_val)\n",
    "acc_score = accuracy_score(y_val, preds)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10472ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<354252x8442 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2929623 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc07b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components = 2  # Start with 2 components\n",
    "# cumulative_explained_variance = 0\n",
    "# while cumulative_explained_variance < 0.9:\n",
    "#     svd = TruncatedSVD(n_components=n_components)\n",
    "#     svd.fit(scaled_tfidf_train)\n",
    "#     cumulative_explained_variance = sum(svd.explained_variance_ratio_)\n",
    "#     n_components += 1\n",
    "\n",
    "# # Decrement n_components by 1 because it was incremented one extra time in the loop\n",
    "# n_components_90 = n_components - 1\n",
    "# print(f\"Number of components needed to retain 90% of variance: {n_components_90}\")\n",
    "\n",
    "# # Now reapply SVD with the found number of components\n",
    "# svd_90 = TruncatedSVD(n_components=n_components_90)\n",
    "# reduced_data_90_train = svd_90.fit_transform(scaled_tfidf_train)\n",
    "# reduced_data_90_val = svd_90.transform(scaled_tfidf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376078e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1000 catches .11 percent\n",
    "# svd = TruncatedSVD(n_components=2000)\n",
    "# svd.fit(scaled_tfidf_train)\n",
    "# cumulative_explained_variance = sum(svd.explained_variance_ratio_)\n",
    "# print(cumulative_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "076fb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_90 = TruncatedSVD(n_components=100)\n",
    "reduced_data_90_train = svd_90.fit_transform(scaled_tfidf_train)\n",
    "reduced_data_90_val = svd_90.transform(scaled_tfidf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5d4229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6122272698189264\n"
     ]
    }
   ],
   "source": [
    "#100 components got .6094\n",
    "#1000 components got .6275\n",
    "lr_clf_vec = LogisticRegression(random_state=42, n_jobs=-1).fit(reduced_data_90_train,y_train)\n",
    "preds = lr_clf_vec.predict(reduced_data_90_val)\n",
    "acc_score = accuracy_score(y_val, preds)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_vec = RandomForestClassifer(random_state=42, max_depth = 10, n_jobs=-1).fit(reduced_data_90,y_train)\n",
    "preds = rf_clf_vec.predict(reduced_data_90_val)\n",
    "acc_score = accuracy_score(y_val, preds)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c486c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gb_model_vec = GradientBoostingClassifier(n_estimators = 200, max_depth = 20,\n",
    "#                                     random_state=42,verbose=1,n_iter_no_change=10,tol=0.001,learning_rate=0.15).fit(scaled_tfidf_train,y_train)\n",
    "# preds = gb_model_vec.predict(scaled_tfidf_val)\n",
    "# acc_score = accuracy_score(y_val, preds)\n",
    "# print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0cef36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contains_wiki_markup</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>only_punctuation</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>ratio_unique_total_words</th>\n",
       "      <th>num_long_words</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>...</th>\n",
       "      <th>gunning_fog_category</th>\n",
       "      <th>smog_index_category</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>high_aoa</th>\n",
       "      <th>low_aoa</th>\n",
       "      <th>concrete_count</th>\n",
       "      <th>non_concrete_count</th>\n",
       "      <th>mean_concreteness</th>\n",
       "      <th>mean_subtlex_us_frequency</th>\n",
       "      <th>only_markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it contains the east half of new guinea island...</td>\n",
       "      <td>26</td>\n",
       "      <td>132</td>\n",
       "      <td>21</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2.964524</td>\n",
       "      <td>288765.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>she wa even more vile and full of sin than aha...</td>\n",
       "      <td>30</td>\n",
       "      <td>132</td>\n",
       "      <td>24</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2.348600</td>\n",
       "      <td>353757.120000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47225</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bar hill is a purpose built village with a pop...</td>\n",
       "      <td>28</td>\n",
       "      <td>136</td>\n",
       "      <td>25</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.848889</td>\n",
       "      <td>284176.194444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322386</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>however , the storm weakened again beause of a...</td>\n",
       "      <td>46</td>\n",
       "      <td>239</td>\n",
       "      <td>39</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2.726429</td>\n",
       "      <td>252962.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391668</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>formula one season sometimes referred to a the...</td>\n",
       "      <td>32</td>\n",
       "      <td>179</td>\n",
       "      <td>29</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2.177826</td>\n",
       "      <td>369295.260870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        contains_wiki_markup  is_numeric  only_punctuation  \\\n",
       "410396                     0           0                 0   \n",
       "158130                     0           0                 0   \n",
       "47225                      1           1                 0   \n",
       "322386                     1           1                 0   \n",
       "391668                     1           1                 0   \n",
       "\n",
       "                                          lemmatized_text  num_words  \\\n",
       "410396  it contains the east half of new guinea island...         26   \n",
       "158130  she wa even more vile and full of sin than aha...         30   \n",
       "47225   bar hill is a purpose built village with a pop...         28   \n",
       "322386  however , the storm weakened again beause of a...         46   \n",
       "391668  formula one season sometimes referred to a the...         32   \n",
       "\n",
       "        num_characters  num_unique_words  ratio_unique_total_words  \\\n",
       "410396             132                21                  0.807692   \n",
       "158130             132                24                  0.800000   \n",
       "47225              136                25                  0.892857   \n",
       "322386             239                39                  0.847826   \n",
       "391668             179                29                  0.906250   \n",
       "\n",
       "        num_long_words  syllable_count  ...  gunning_fog_category  \\\n",
       "410396               4              31  ...                     0   \n",
       "158130               1              29  ...                     1   \n",
       "47225                6              34  ...                     1   \n",
       "322386              10              55  ...                     1   \n",
       "391668               6              45  ...                     1   \n",
       "\n",
       "        smog_index_category  dale_chall  high_aoa  low_aoa  concrete_count  \\\n",
       "410396                    0          18         0       22               9   \n",
       "158130                    0          23         2       23               5   \n",
       "47225                     0          15         0       18               9   \n",
       "322386                    0          16         1       22               9   \n",
       "391668                    0          20         4       23               5   \n",
       "\n",
       "        non_concrete_count  mean_concreteness  mean_subtlex_us_frequency  \\\n",
       "410396                  12           2.964524              288765.500000   \n",
       "158130                  20           2.348600              353757.120000   \n",
       "47225                    9           2.848889              284176.194444   \n",
       "322386                  12           2.726429              252962.000000   \n",
       "391668                  18           2.177826              369295.260870   \n",
       "\n",
       "        only_markup  \n",
       "410396            0  \n",
       "158130            0  \n",
       "47225             0  \n",
       "322386            0  \n",
       "391668            0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb70ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.6647418260925203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#with 1000 svd components and additional features, score goes to 0.6647\n",
    "# Scale the additional features\n",
    "scaler_additional = StandardScaler()\n",
    "num_features_train = scaler_additional.fit_transform(X_train.drop('lemmatized_text',axis=1))\n",
    "num_features_val = scaler_additional.transform(X_val.drop('lemmatized_text',axis=1))\n",
    "\n",
    "# Concatenate SVD features with additional features\n",
    "combined_features_train = np.hstack((reduced_data_90_train, num_features_train))\n",
    "combined_features_val = np.hstack((reduced_data_90_val, num_features_val))\n",
    "\n",
    "# Train a classifier (e.g., Random Forest)\n",
    "classifier = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "classifier.fit(combined_features_train, y_train)  # Assuming y_train is your target for the training set\n",
    "\n",
    "# Evaluate the classifier on the validation set\n",
    "score = classifier.score(combined_features_val, y_val)  # Assuming y_val is your target for the validation set\n",
    "print(f\"Validation Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04c71149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a classifier (e.g., Random Forest)\n",
    "# classifier = LogisticRegression(random_state=42,solver='saga', max_iter=1000,C=0.1, n_jobs=-1)\n",
    "# classifier.fit(combined_features_train, y_train)  \n",
    "\n",
    "# # Evaluate the classifier on the validation set\n",
    "# score = classifier.score(combined_features_val, y_val)  \n",
    "# print(f\"Validation Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_vec = RandomForestClassifer(random_state=42, max_depth = 10, n_jobs=-1).fit(combined_features_train,y_train)\n",
    "preds = rf_clf_vec.predict(combine_features_val)\n",
    "acc_score = accuracy_score(y_val, preds)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6a413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n"
     ]
    }
   ],
   "source": [
    "gb_model_vec = GradientBoostingClassifier(n_estimators = 300, max_depth = 15,\n",
    "                                    random_state=42,verbose=1,n_iter_no_change=10,tol=0.001,n_jobs=-1).fit(combined_features_train,y_train)\n",
    "score = gb_model_vec.score(combined_features_val, y_val) \n",
    "print(f\"Validation Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec93848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd4fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587346f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c07f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde4232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7931d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e5212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f51666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "# Load the pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to encode text to BERT embeddings\n",
    "def encode_text(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Get the output from BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the embeddings (use the last hidden state)\n",
    "    # The output is in shape (batch_size, sequence_length, hidden_size)\n",
    "    # We can use mean pooling to get fixed size encoding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Apply the function to the 'lemmatized_text' column\n",
    "X['bert_embeddings'] = X['lemmatized_text'].apply(encode_text)\n",
    "print('X dataframe done')\n",
    "X_test['bert_embeddings'] = X_test['lemmatized_text'].apply(encode_text)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add bert embeddings to main dataframes and then pickle again\n",
    "train_df['bert_embeddings'] = X['bert_embeddings']\n",
    "test_df['bert_embeddings'] = X_test['bert_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert the embeddings to numpy array (df['bert_embeddings'] is a series of tensors)\n",
    "embeddings = torch.stack(df['bert_embeddings'].tolist()).numpy()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classifier\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "score = f1_score(y_test, predictions)\n",
    "print(f'F1 Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaling to the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert the scaled features to a PyTorch tensor\n",
    "inputs = torch.tensor(scaled_features, dtype=torch.float32)\n",
    "\n",
    "# Define the remaining parts of the network (e.g., architecture, loss function, optimizer) and train the model\n",
    "# ...\n",
    "\n",
    "# Example usage:\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the network architecture\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Define the hyperparameters\n",
    "input_size = 784  # Input size for MNIST dataset (28x28 = 784)\n",
    "hidden_size = 256  # Number of units in the hidden layer\n",
    "num_classes = 10  # Number of output classes for MNIST (0-9 digits)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the model\n",
    "model = FullyConnectedNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Example usage:\n",
    "# Forward pass\n",
    "inputs = torch.randn(100, input_size)  # Random input data of size (batch_size, input_size)\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Backward and optimize\n",
    "labels = torch.randint(num_classes, (100,))  # Random labels of size (batch_size,)\n",
    "loss = criterion(outputs, labels)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-chapter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-romania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-increase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-prayer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter grid for tuning\n",
    "# param_grid = {\n",
    "#     'classifier__n_estimators': [100, 200, 300, 400],\n",
    "#     'classifier__max_depth': [3, 5, 7, 9, 11],\n",
    "#     'classifier__min_samples_split': [2, 5, 7],\n",
    "# }\n",
    "\n",
    "# # Create the F1 scorer\n",
    "# scorer = make_scorer(f1_score)\n",
    "# # Perform grid search cross-validation\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy',refit=True,return_train_score=True,\n",
    "#                             verbose=1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best model and its performance\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_val)\n",
    "# report = classification_report(y_val, y_pred)\n",
    "# print(\"Best Model Performance:\")\n",
    "# print(report)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-campus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=150)  # Specify the number of components you want to keep\n",
    "X_svd = svd.fit_transform(X_train_vec)\n",
    "X_svd_val = svd.transform(X_val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_svd_clf = LogisticRegression(random_state=42).fit(X_svd, y_train)\n",
    "lr_preds = lr_svd_clf.predict(X_svd_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, lr_preds)\n",
    "precision = precision_score(y_val, lr_preds)\n",
    "recall = recall_score(y_val, lr_preds)\n",
    "f1 = f1_score(y_val, lr_preds)\n",
    "roc_auc = roc_auc_score(y_val, lr_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.drop(['original_text','clean_text','stem_text','pos_counts'],axis=1)\n",
    "features = features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on both tf-idf and features\n",
    "X_additional = X_train[features].values\n",
    "\n",
    "# # Concatenate the arrays together\n",
    "X_train_arr = np.concatenate((X_svd, X_additional), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_additional_val = X_val[features].values\n",
    "\n",
    "# # Concatenate the arrays together\n",
    "X_val_arr = np.concatenate((X_svd_val, X_additional_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline with .yaml for easy git changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_arr_clf = LogisticRegression(random_state=42).fit(X_train_arr, y_train)\n",
    "lr_preds = lr_arr_clf.predict(X_val_arr)\n",
    "\n",
    "accuracy = accuracy_score(y_val, lr_preds)\n",
    "precision = precision_score(y_val, lr_preds)\n",
    "recall = recall_score(y_val, lr_preds)\n",
    "f1 = f1_score(y_val, lr_preds)\n",
    "roc_auc = roc_auc_score(y_val, lr_preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-object",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-message",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-little",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-toddler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-commerce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-response",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
